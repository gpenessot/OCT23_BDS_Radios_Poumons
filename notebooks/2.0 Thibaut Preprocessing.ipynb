{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet radiologie bootcamp DST : Etape 2, Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plan de preprocessing : \n",
    "* Ouvrir chaque image avec son masque associé\n",
    "* Convertir en Grayscale\n",
    "* Redimensionner les images à la taille des masques (256 * 256)\n",
    "* Appliquer les masques\n",
    "* Equilibrer le nouveau dataset\n",
    "* Séparer le dataset en ensemble d'entraînement (70%), de validation (15%) et de test (15%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import des bibliothèques\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import os, pathlib\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil #pour copier des fichiers vers les dossiers de preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etape 1 : création des images masquées et en échelles de gris\n",
    "* Ouvrir chaque image en grayscale en itérant sur les dossiers\n",
    "* Ouvrir le masque associé en grayscale\n",
    "* Resizer l'image en 256*256\n",
    "* Appliquer le masque\n",
    "* Enregistrer l'image dans un nouveau dossier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sous-fonction qui ouvre une image à partir du filepath, la convertit en Grayscale et la redimensionne en 256*256\n",
    "#En input : le filepath d'une image dans le dossier \"image\" => plutôt retravailler le masque\n",
    "def load_and_resize(file):\n",
    "    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    img_resized = cv2.resize(img, (256, 256))\n",
    "    return img_resized\n",
    "\n",
    "#Sous-fonction qui va chercher le masque et le convertit en Grayscale\n",
    "#En input : le filepath d'une image dans le dossier \"image\" qui est l'input de la fonction finale\n",
    "def load_mask(file):\n",
    "    mask_path = file.replace(\"images\",\"masks\")\n",
    "    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "    return mask\n",
    "\n",
    "#Fonction qui applique le masque et enregistre l'image ainsi préprocessée dans un nouveau dossier\n",
    "#Input : image et masque (données d'origine), nom du fichier et chemin du dossier cible pour l'enregistrement\n",
    "def get_masked_imgs(sourceimg, nom_cible, dossier_cible):\n",
    "    img_resized = load_and_resize(sourceimg)\n",
    "    mask = load_mask(sourceimg)\n",
    "    img_masked = cv2.bitwise_and(img_resized, mask)\n",
    "    cv2.imwrite(os.path.join(dossier_cible, nom_cible), img_masked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test sur 1 fichier\n",
    "fichier = \"C:\\\\Users\\\\thiba\\\\Documents\\\\Projets data\\\\Projet-radio-DST_TG\\\\data\\\\Viral Pneumonia\\\\images\\\\Viral Pneumonia-14.png\"\n",
    "nom_cible = os.path.split(fichier)[1]\n",
    "dossier_cible = \"..\\\\data\\\\Preprocessing_1\"\n",
    "\n",
    "get_masked_imgs(fichier, nom_cible, dossier_cible)\n",
    "\n",
    "\n",
    "\n",
    "#print(img_resized.shape)\n",
    "#print(mask.shape)\n",
    "#plt.figure(figsize=(15, 5))\n",
    "#plt.subplot(131)\n",
    "#plt.imshow(img_resized, cmap = \"Greys_r\")\n",
    "#plt.subplot(132)\n",
    "#plt.imshow(mask, cmap = \"Greys_r\")\n",
    "#plt.subplot(133)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.72it/s]\n"
     ]
    }
   ],
   "source": [
    "#Définition des dossiers d'origine et cible, et lancement des fonctions => voir le script python dans SRC\n",
    "\n",
    "#dossiers_source_dict = {\"COVID\" : \"../data/COVID/images/\", \"NORMAL\" : \"../data/Normal/images/\", \"VIRAL_PNEUMONIA\" : \"../data/Viral Pneumonia/images/\", \"LUNG_OPACITY\" : \"../data/Lung_Opacity/images/\" }\n",
    "dossiers_source_dict = {\"TEST\" : \"../data/test/images/\"}\n",
    "dossier_cible = \"..\\\\data\\\\Preprocessing_1\"\n",
    "\n",
    "#Itérer sur les dossiers pour récupérer les fichiers images \n",
    "for n,filepath in dossiers_source_dict.items():\n",
    "    for f in tqdm(os.listdir(filepath)):\n",
    "        nom_cible = f\n",
    "        file = os.path.join(filepath, f)\n",
    "        get_masked_imgs(file, nom_cible, dossier_cible)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 2 : Equilibrage des classes par sous-échantillonage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import de la base excel metadata\n",
    "meta_Covid = pd.read_excel(\"../data/COVID.metadata.xlsx\")\n",
    "meta_Covid.insert(loc = 0, column=\"CLASS\", value =  \"COVID\")\n",
    "meta_Normal = pd.read_excel(\"../data/Normal.metadata.xlsx\")\n",
    "meta_Normal.insert(loc = 0, column=\"CLASS\", value =  \"NORMAL\")\n",
    "meta_VPneu = pd.read_excel(\"../data/Viral Pneumonia.metadata.xlsx\")\n",
    "meta_VPneu.insert(loc = 0, column=\"CLASS\", value =  \"VIRAL_PNEUMONIA\")\n",
    "meta_LO = pd.read_excel(\"../data/Lung_Opacity.metadata.xlsx\")\n",
    "meta_LO.insert(loc = 0, column=\"CLASS\", value =  \"LUNG_OPACITY\")\n",
    "#Fusion des 4 metafichiers dans un dataframe\n",
    "metadata = pd.concat([meta_Covid, meta_LO, meta_Normal, meta_VPneu], axis = 0)\n",
    "#Enregistrement en csv\n",
    "metadata.to_csv(\"../data/metadata_compil.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "COVID              1345\n",
       "LUNG_OPACITY       1345\n",
       "NORMAL             1345\n",
       "VIRAL_PNEUMONIA    1345\n",
       "Name: CLASS, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Nb de valeurs par classe dans metadata\n",
    "print(len(metadata))\n",
    "metadata[\"CLASS\"].value_counts()\n",
    "\n",
    "#Utilisation d'un RandomUnderSampler pour équilibrer le dataset\n",
    "ru = RandomUnderSampler(random_state = 123, replacement = False)\n",
    "meta_ru, y_ru = ru.fit_resample(metadata, metadata[\"CLASS\"])\n",
    "meta_ru.head()\n",
    "meta_ru[\"CLASS\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5380"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_ru[\"CLASS\"].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meta Train :\n",
      " VIRAL_PNEUMONIA    942\n",
      "COVID              942\n",
      "NORMAL             941\n",
      "LUNG_OPACITY       941\n",
      "Name: CLASS, dtype: int64\n",
      "meta VAL :\n",
      " LUNG_OPACITY       202\n",
      "VIRAL_PNEUMONIA    202\n",
      "NORMAL             202\n",
      "COVID              201\n",
      "Name: CLASS, dtype: int64\n",
      "meta TEST :\n",
      " NORMAL             202\n",
      "COVID              202\n",
      "LUNG_OPACITY       202\n",
      "VIRAL_PNEUMONIA    201\n",
      "Name: CLASS, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TRAIN    3766\n",
       "VAL       807\n",
       "TEST      807\n",
       "Name: SET, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Sélection aléatoire et enregistrement des fichiers dans les dossiers TRAIN (70%), VALIDATE (15%), TEST (15%)\n",
    "# Séparation jeu de TRAIN à 70/30\n",
    "meta_TRAIN, meta_TESTVAL, y1, y2 = train_test_split(meta_ru, y_ru, test_size = 0.3, random_state = 123, stratify = y_ru)\n",
    "\n",
    "#Séparation du jeu de VALIDATION et TEST à 50/50\n",
    "meta_VAL, meta_TEST, y3, y4 = train_test_split(meta_TESTVAL, y2, test_size = 0.5, random_state = 123, stratify = y2)\n",
    "\n",
    "print(\"meta Train :\\n\", meta_TRAIN[\"CLASS\"].value_counts())\n",
    "print(\"meta VAL :\\n\", meta_VAL[\"CLASS\"].value_counts())\n",
    "print(\"meta TEST :\\n\", meta_TEST[\"CLASS\"].value_counts())\n",
    "meta_TRAIN.head()\n",
    "\n",
    "meta_TRAIN[\"SET\"] = \"TRAIN\"\n",
    "meta_VAL[\"SET\"] = \"VAL\"\n",
    "meta_TEST[\"SET\"] = \"TEST\"\n",
    "meta_dataset = pd.concat([meta_TRAIN, meta_VAL, meta_TEST], axis = 0)\n",
    "meta_dataset[\"SET\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etape 3 : enregistrement des 3 datasets dans 3 sous-dossiers TRAIN, VAL, TEST du dossier PREPROCESSING_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>FILE NAME</th>\n",
       "      <th>FORMAT</th>\n",
       "      <th>SIZE</th>\n",
       "      <th>URL</th>\n",
       "      <th>SET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>VIRAL_PNEUMONIA</td>\n",
       "      <td>Viral Pneumonia-46</td>\n",
       "      <td>PNG</td>\n",
       "      <td>256*256</td>\n",
       "      <td>https://www.kaggle.com/paultimothymooney/chest...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-2461</td>\n",
       "      <td>PNG</td>\n",
       "      <td>256*256</td>\n",
       "      <td>https://bimcv.cipf.es/bimcv-projects/bimcv-cov...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4244</th>\n",
       "      <td>VIRAL_PNEUMONIA</td>\n",
       "      <td>Viral Pneumonia-210</td>\n",
       "      <td>PNG</td>\n",
       "      <td>256*256</td>\n",
       "      <td>https://www.kaggle.com/paultimothymooney/chest...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5306</th>\n",
       "      <td>VIRAL_PNEUMONIA</td>\n",
       "      <td>Viral Pneumonia-1272</td>\n",
       "      <td>PNG</td>\n",
       "      <td>256*256</td>\n",
       "      <td>https://www.kaggle.com/paultimothymooney/chest...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>COVID</td>\n",
       "      <td>COVID-1693</td>\n",
       "      <td>PNG</td>\n",
       "      <td>256*256</td>\n",
       "      <td>https://bimcv.cipf.es/bimcv-projects/bimcv-cov...</td>\n",
       "      <td>TRAIN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                CLASS             FILE NAME FORMAT     SIZE  \\\n",
       "4080  VIRAL_PNEUMONIA    Viral Pneumonia-46    PNG  256*256   \n",
       "1106            COVID            COVID-2461    PNG  256*256   \n",
       "4244  VIRAL_PNEUMONIA   Viral Pneumonia-210    PNG  256*256   \n",
       "5306  VIRAL_PNEUMONIA  Viral Pneumonia-1272    PNG  256*256   \n",
       "1058            COVID            COVID-1693    PNG  256*256   \n",
       "\n",
       "                                                    URL    SET  \n",
       "4080  https://www.kaggle.com/paultimothymooney/chest...  TRAIN  \n",
       "1106  https://bimcv.cipf.es/bimcv-projects/bimcv-cov...  TRAIN  \n",
       "4244  https://www.kaggle.com/paultimothymooney/chest...  TRAIN  \n",
       "5306  https://www.kaggle.com/paultimothymooney/chest...  TRAIN  \n",
       "1058  https://bimcv.cipf.es/bimcv-projects/bimcv-cov...  TRAIN  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5380it [01:45, 50.92it/s]\n"
     ]
    }
   ],
   "source": [
    "dossier_source = \"..\\\\data\\\\Preprocessing_1\"\n",
    "dossiers_cibles_dict = {\"TRAIN\" : \"..\\\\data\\\\Preprocessing_2\\Train\", \"VAL\" : \"..\\\\data\\\\Preprocessing_2\\Train\", \"TEST\" : \"..\\\\data\\\\Preprocessing_2\\Train\"}\n",
    "\n",
    "#Fonction pour copier les fichiers dans le dossier cible\n",
    "def copy_to_folder(filename, source_folder, target_folder):\n",
    "    filename = filename + \".png\"\n",
    "    #chemin d'accès au fichier soruce\n",
    "    src = os.path.join(source_folder, filename)\n",
    "    #chemin d'accès du fichier copié\n",
    "    dst = os.path.join(target_folder, filename)\n",
    "    #copie\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "#Itération sur les noms de fichiers retenus par le TRAIN TEST SPLIT\n",
    "for index, row in tqdm(meta_dataset.iterrows()):\n",
    "    dossier_cible = dossiers_cibles_dict[row[\"SET\"]]\n",
    "    copy_to_folder(row[\"FILE NAME\"], dossier_source, dossier_cible)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
